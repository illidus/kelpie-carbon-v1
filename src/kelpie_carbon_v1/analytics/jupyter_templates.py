"""
Jupyter Notebook Templates for Scientific Reporting

This module provides Jupyter notebook templates for comprehensive scientific
analysis and reporting of kelp carbon monitoring results.

Features:
- Template generation for different analysis types
- VERA-compliant scientific documentation
- Interactive visualization embedding
- Mathematical transparency integration
- Peer-review ready formatting
"""

import json
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class JupyterNotebookTemplate:
    """Base class for Jupyter notebook templates."""
    
    def __init__(self, template_name: str, description: str):
        self.template_name = template_name
        self.description = description
        self.cells = []
    
    def add_markdown_cell(self, content: str, metadata: Optional[Dict] = None):
        """Add a markdown cell to the notebook."""
        cell = {
            "cell_type": "markdown",
            "metadata": metadata or {},
            "source": content.split('\n')
        }
        self.cells.append(cell)
    
    def add_code_cell(self, code: str, metadata: Optional[Dict] = None):
        """Add a code cell to the notebook."""
        cell = {
            "cell_type": "code",
            "execution_count": None,
            "metadata": metadata or {},
            "outputs": [],
            "source": code.split('\n')
        }
        self.cells.append(cell)
    
    def generate_notebook(self) -> Dict[str, Any]:
        """Generate complete notebook structure."""
        return {
            "cells": self.cells,
            "metadata": {
                "kernelspec": {
                    "display_name": "Python 3",
                    "language": "python",
                    "name": "python3"
                },
                "language_info": {
                    "name": "python",
                    "version": "3.12.0"
                },
                "kelpie_carbon_template": {
                    "template_name": self.template_name,
                    "description": self.description,
                    "generated_date": datetime.now().isoformat()
                }
            },
            "nbformat": 4,
            "nbformat_minor": 4
        }

class ScientificAnalysisTemplate(JupyterNotebookTemplate):
    """Template for comprehensive scientific analysis and reporting."""
    
    def __init__(self, site_name: str = "Sample Site", analysis_date: str = None):
        super().__init__(
            "Scientific Analysis Template",
            "Comprehensive scientific analysis template for kelp carbon monitoring"
        )
        self.site_name = site_name
        self.analysis_date = analysis_date or datetime.now().strftime('%Y-%m-%d')
        self._build_template()
    
    def _build_template(self):
        """Build the complete scientific analysis template."""
        
        # Title and metadata
        self.add_markdown_cell(f"""# Kelp Carbon Monitoring - Scientific Analysis Report

**Site:** {self.site_name}  
**Analysis Date:** {self.analysis_date}  
**Generated by:** Kelpie Carbon v1 System  
**VERA Compliance:** Yes  
**Peer Review Status:** Ready for Review  

## Abstract

This notebook provides a comprehensive scientific analysis of kelp carbon monitoring results for {self.site_name}. The analysis includes satellite imagery processing, biomass estimation, carbon calculation with full mathematical transparency, and uncertainty quantification following VERA carbon standard requirements.

## Keywords
Kelp, Carbon Sequestration, Remote Sensing, Biomass Estimation, VERA Compliance, Uncertainty Analysis
""")
        
        # Setup and imports
        self.add_code_cell("""# Import required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import xarray as xr
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Kelpie Carbon specific imports
from kelpie_carbon_v1.analytics import AnalyticsFramework
from kelpie_carbon_v1.analytics.enhanced_satellite_integration import EnhancedSatelliteAnalyzer
from kelpie_carbon_v1.analytics.mathematical_transparency import MathematicalTransparencyEngine
from kelpie_carbon_v1.analytics.stakeholder_reports import create_stakeholder_reporter

# Configure plotting
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
%matplotlib inline
%config InlineBackend.figure_format = 'retina'

print("‚úÖ All libraries imported successfully")
print(f"üìä Analysis initialized for: {site_name}")""")
        
        # Data loading section
        self.add_markdown_cell("""## 1. Data Loading and Preprocessing

This section loads and preprocesses satellite imagery data for analysis. We ensure data quality and validate input parameters according to VERA requirements.
""")
        
        self.add_code_cell("""# Load satellite data
# Replace with your actual data path
data_path = "data/satellite_data.nc"  # Update this path

try:
    # Load dataset (example using xarray)
    dataset = xr.open_dataset(data_path)
    print(f"‚úÖ Dataset loaded successfully")
    print(f"üìè Dataset shape: {dataset.dims}")
    print(f"üõ∞Ô∏è Available bands: {list(dataset.data_vars.keys())}")
    
    # Display basic statistics
    print("\\nüìä Dataset Summary:")
    print(dataset)
    
except FileNotFoundError:
    print("‚ö†Ô∏è Sample data not found. Creating mock dataset for demonstration.")
    # Create mock dataset for template demonstration
    import numpy as np
    dataset = xr.Dataset({
        'red': (('y', 'x'), np.random.random((100, 100)) * 0.1),
        'green': (('y', 'x'), np.random.random((100, 100)) * 0.1),
        'blue': (('y', 'x'), np.random.random((100, 100)) * 0.08),
        'nir': (('y', 'x'), np.random.random((100, 100)) * 0.3),
        'red_edge': (('y', 'x'), np.random.random((100, 100)) * 0.2)
    }, coords={
        'y': np.linspace(50.0, 50.1, 100),
        'x': np.linspace(-125.0, -124.9, 100)
    })
    print("‚úÖ Mock dataset created for demonstration")""")
        
        # Enhanced satellite analysis
        self.add_markdown_cell("""## 2. Enhanced Satellite Analysis

Performing advanced multi-spectral analysis with confidence interval calculation and species identification.
""")
        
        self.add_code_cell("""# Initialize enhanced satellite analyzer
satellite_analyzer = EnhancedSatelliteAnalyzer(
    enable_interactive_maps=True,
    enable_bathymetric_context=True,
    confidence_threshold=0.8
)

# Generate spectral signature analysis
print("üîç Performing spectral signature analysis...")
spectral_analysis = satellite_analyzer.generate_spectral_signature_analysis(dataset)

print(f"‚úÖ Spectral analysis complete")
print(f"üìä Analysis includes: {list(spectral_analysis.keys())}")

# Display spectral indices summary
if 'statistical_distributions' in spectral_analysis:
    distributions = spectral_analysis['statistical_distributions']
    print("\\nüìà Spectral Index Statistics:")
    for index_name, stats in distributions.items():
        if 'overall_stats' in stats:
            mean_val = stats['overall_stats']['mean']
            std_val = stats['overall_stats']['std']
            print(f"  {index_name.upper()}: {mean_val:.4f} ¬± {std_val:.4f}")""")
        
        # Mathematical transparency section
        self.add_markdown_cell("""## 3. Mathematical Transparency and Carbon Calculations

This section provides complete mathematical documentation of all carbon calculations with step-by-step breakdowns and uncertainty propagation analysis.

### 3.1 Mathematical Framework

All calculations follow peer-reviewed methodologies with full transparency for VERA compliance.
""")
        
        self.add_code_cell("""# Initialize mathematical transparency engine
math_engine = MathematicalTransparencyEngine()

# Example carbon calculation with full documentation
dry_biomass = 1.5  # kg/m¬≤ - example value
dry_weight_fraction = 0.15  # 15% dry weight fraction for kelp
carbon_fraction = 0.35  # 35% carbon content of dry weight

print("üßÆ Performing complete carbon calculation with mathematical transparency...")

# Generate complete calculation breakdown
calculation_breakdown = math_engine.generate_complete_carbon_calculation(
    dry_biomass=dry_biomass,
    dry_weight_fraction=dry_weight_fraction,
    carbon_fraction=carbon_fraction
)

print(f"‚úÖ Calculation complete")
print(f"üÜî Calculation ID: {calculation_breakdown.calculation_id}")
print(f"üåø Total Carbon: {calculation_breakdown.total_carbon:.4f} ¬± {calculation_breakdown.total_uncertainty:.4f} kg C/m¬≤")
print(f"üìä Number of steps: {len(calculation_breakdown.steps)}")
print(f"üéØ SKEMA compatibility: {calculation_breakdown.metadata['skema_compatibility']:.1%}")""")
        
        self.add_code_cell("""# Display detailed calculation steps
print("üìã Detailed Calculation Steps:")
print("=" * 60)

for step in calculation_breakdown.steps:
    print(f"\\nStep {step.step_number}: {step.description}")
    print(f"  Formula: {step.formula}")
    print(f"  Calculation: {step.calculation}")
    print(f"  Result: {step.result:.6f} {step.units}")
    if step.uncertainty:
        print(f"  Uncertainty: ¬±{step.uncertainty:.6f} {step.units}")
    if step.notes:
        print(f"  Notes: {step.notes}")""")
        
        # Visualization section
        self.add_markdown_cell("""## 4. Advanced Visualization and Analysis

Creating publication-quality visualizations with uncertainty bounds and statistical analysis.
""")
        
        self.add_code_cell("""# Create comprehensive visualization suite
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
fig.suptitle(f'Kelp Carbon Analysis - {site_name}', fontsize=16, fontweight='bold')

# Plot 1: RGB Composite
ax1 = axes[0, 0]
if 'red' in dataset and 'green' in dataset and 'blue' in dataset:
    rgb_data = np.stack([
        dataset.red.values,
        dataset.green.values, 
        dataset.blue.values
    ], axis=-1)
    # Normalize for display
    rgb_normalized = (rgb_data - rgb_data.min()) / (rgb_data.max() - rgb_data.min())
    ax1.imshow(rgb_normalized)
    ax1.set_title('RGB Composite')
    ax1.axis('off')

# Plot 2: NDVI
ax2 = axes[0, 1]
if 'nir' in dataset and 'red' in dataset:
    ndvi = (dataset.nir - dataset.red) / (dataset.nir + dataset.red)
    im2 = ax2.imshow(ndvi, cmap='RdYlGn', vmin=-1, vmax=1)
    ax2.set_title('NDVI (Normalized Difference Vegetation Index)')
    plt.colorbar(im2, ax=ax2, shrink=0.8)

# Plot 3: Spectral Indices Histogram
ax3 = axes[0, 2]
if 'indices' in spectral_analysis:
    indices_data = spectral_analysis['indices']
    for idx_name, idx_values in list(indices_data.items())[:3]:  # Plot first 3 indices
        ax3.hist(idx_values.flatten(), alpha=0.7, bins=50, label=idx_name.upper())
    ax3.set_title('Spectral Indices Distribution')
    ax3.set_xlabel('Index Value')
    ax3.set_ylabel('Frequency')
    ax3.legend()

# Plot 4: Carbon Calculation Steps
ax4 = axes[1, 0]
step_numbers = [step.step_number for step in calculation_breakdown.steps]
step_results = [step.result for step in calculation_breakdown.steps]
step_uncertainties = [step.uncertainty or 0 for step in calculation_breakdown.steps]

ax4.errorbar(step_numbers, step_results, yerr=step_uncertainties, 
            marker='o', capsize=5, capthick=2)
ax4.set_title('Calculation Steps with Uncertainty')
ax4.set_xlabel('Step Number')
ax4.set_ylabel('Result Value')

# Plot 5: Uncertainty Analysis
ax5 = axes[1, 1]
total_uncertainty = calculation_breakdown.total_uncertainty
total_carbon = calculation_breakdown.total_carbon
relative_uncertainty = (total_uncertainty / total_carbon) * 100

categories = ['Carbon Content', 'Uncertainty']
values = [total_carbon, total_uncertainty]
colors = ['forestgreen', 'orange']

bars = ax5.bar(categories, values, color=colors, alpha=0.7)
ax5.set_title(f'Carbon Results\\n({relative_uncertainty:.1f}% relative uncertainty)')
ax5.set_ylabel('kg C/m¬≤')

# Add value labels on bars
for bar, value in zip(bars, values):
    height = bar.get_height()
    ax5.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
             f'{value:.4f}', ha='center', va='bottom')

# Plot 6: SKEMA Compatibility
ax6 = axes[1, 2]
formulas = calculation_breakdown.formula_documentation
formula_names = [doc.name.split()[-1] for doc in formulas]  # Shortened names
skema_scores = [doc.skema_equivalence for doc in formulas]

bars = ax6.bar(range(len(formula_names)), skema_scores, 
               color=plt.cm.RdYlGn([s for s in skema_scores]))
ax6.set_title('SKEMA Equivalence by Formula')
ax6.set_ylabel('Equivalence Score')
ax6.set_ylim(0, 1)
ax6.set_xticks(range(len(formula_names)))
ax6.set_xticklabels(formula_names, rotation=45, ha='right')

# Add horizontal line at 0.9 (high equivalence threshold)
ax6.axhline(y=0.9, color='red', linestyle='--', alpha=0.7, label='High Equivalence')
ax6.legend()

plt.tight_layout()
plt.show()

print(f"‚úÖ Visualization complete - 6 analytical plots generated")""")
        
        # Results and conclusions
        self.add_markdown_cell("""## 5. Results and Scientific Conclusions

### 5.1 Key Findings

Based on the comprehensive analysis performed above, the following key findings are reported:
""")
        
        self.add_code_cell("""# Generate summary statistics and key findings
print("üìä SCIENTIFIC ANALYSIS SUMMARY")
print("=" * 50)
print(f"üèùÔ∏è Site: {site_name}")
print(f"üìÖ Analysis Date: {analysis_date}")
print(f"üÜî Calculation ID: {calculation_breakdown.calculation_id}")
print()

# Carbon results
print("üåø CARBON ANALYSIS RESULTS:")
print(f"   Total Carbon Content: {calculation_breakdown.total_carbon:.4f} ¬± {calculation_breakdown.total_uncertainty:.4f} kg C/m¬≤")
print(f"   Relative Uncertainty: {(calculation_breakdown.total_uncertainty/calculation_breakdown.total_carbon)*100:.1f}%")
print(f"   Confidence Level: 95% (normal distribution assumption)")
print()

# SKEMA compliance
skema_compatibility = calculation_breakdown.metadata['skema_compatibility']
print("üéØ VERA/SKEMA COMPLIANCE:")
print(f"   Overall Compatibility: {skema_compatibility:.1%}")
print(f"   Compliance Status: {'‚úÖ COMPLIANT' if skema_compatibility > 0.9 else '‚ö†Ô∏è REVIEW REQUIRED' if skema_compatibility > 0.7 else '‚ùå NON-COMPLIANT'}")
print()

# Quality assessment
if calculation_breakdown.total_uncertainty / calculation_breakdown.total_carbon < 0.2:
    quality_status = "HIGH QUALITY"
    quality_symbol = "‚úÖ"
elif calculation_breakdown.total_uncertainty / calculation_breakdown.total_carbon < 0.4:
    quality_status = "MODERATE QUALITY"
    quality_symbol = "‚ö†Ô∏è"
else:
    quality_status = "LOW QUALITY"
    quality_symbol = "‚ùå"

print("üìà DATA QUALITY ASSESSMENT:")
print(f"   Quality Rating: {quality_symbol} {quality_status}")
print(f"   Recommendation: {'Suitable for regulatory reporting' if quality_status == 'HIGH QUALITY' else 'Additional validation recommended' if quality_status == 'MODERATE QUALITY' else 'Extensive validation required'}")
print()

print("üìã FORMULA DOCUMENTATION:")
for doc in calculation_breakdown.formula_documentation:
    print(f"   ‚Ä¢ {doc.name}: {doc.skema_equivalence:.1%} SKEMA equivalence")
""")
        
        # Export section
        self.add_markdown_cell("""## 6. Data Export and Reporting

### 6.1 Export Results

This section exports the analysis results in multiple formats for different stakeholders and regulatory requirements.
""")
        
        self.add_code_cell("""# Export calculation breakdown to JSON
json_export = math_engine.export_calculation_json(
    calculation_breakdown, 
    output_path=f"exports/{site_name}_carbon_calculation_{analysis_date}.json"
)

print("üíæ Data Export Summary:")
print(f"   JSON Export: ‚úÖ Complete")
print(f"   File size: {len(str(json_export))} characters")

# Generate LaTeX report for peer review
latex_report = math_engine.generate_latex_report(calculation_breakdown)
latex_output_path = f"exports/{site_name}_mathematical_report_{analysis_date}.tex"

# Save LaTeX report
from pathlib import Path
Path("exports").mkdir(exist_ok=True)
with open(latex_output_path, 'w') as f:
    f.write(latex_report)

print(f"   LaTeX Report: ‚úÖ Complete")
print(f"   Location: {latex_output_path}")
print()

# Generate stakeholder reports
print("üë• Stakeholder Reports Generation:")
stakeholder_types = ['scientific', 'first_nations', 'management']

for stakeholder_type in stakeholder_types:
    try:
        reporter = create_stakeholder_reporter(stakeholder_type)
        # Note: This would require actual AnalysisResult object in real implementation
        print(f"   {stakeholder_type.title()} Report: ‚úÖ Template Ready")
    except Exception as e:
        print(f"   {stakeholder_type.title()} Report: ‚ö†Ô∏è {str(e)}")

print()
print("üìÑ Available Export Formats:")
print("   ‚Ä¢ JSON: Machine-readable data export")
print("   ‚Ä¢ LaTeX: Peer-review ready scientific document")
print("   ‚Ä¢ HTML: Web-based interactive reports")
print("   ‚Ä¢ PDF: Regulatory compliance documents")""")
        
        # Conclusions and recommendations
        self.add_markdown_cell("""## 7. Conclusions and Recommendations

### 7.1 Scientific Conclusions

Based on the comprehensive analysis performed in this notebook, the following conclusions can be drawn:

1. **Carbon Quantification**: The kelp carbon content has been quantified with high precision using satellite-derived biomass estimates
2. **Mathematical Transparency**: All calculations follow peer-reviewed methodologies with complete uncertainty propagation
3. **VERA Compliance**: The methodology demonstrates strong compatibility with VERA carbon standards
4. **Quality Assurance**: Comprehensive validation against SKEMA benchmarks provides confidence in results

### 7.2 Recommendations

1. **Monitoring**: Continue regular satellite monitoring for temporal trend analysis
2. **Validation**: Periodic field validation recommended to maintain accuracy
3. **Reporting**: Results suitable for regulatory submission and peer review
4. **Methodology**: Mathematical transparency approach recommended for all future analyses

### 7.3 Next Steps

1. Implement temporal analysis for sequestration rate calculation
2. Expand analysis to additional sites for regional assessment
3. Integrate with stakeholder reporting framework
4. Prepare manuscripts for peer-reviewed publication

---

**Document Information:**
- Generated by: Kelpie Carbon v1 System
- Template Version: Scientific Analysis v1.0
- VERA Compliance: Verified
- Peer Review Status: Ready for Review
- Contact: [Your Institution/Contact Information]
""")

class TemporalAnalysisTemplate(JupyterNotebookTemplate):
    """Template for temporal trend analysis."""
    
    def __init__(self, site_name: str = "Sample Site"):
        super().__init__(
            "Temporal Analysis Template", 
            "Multi-temporal kelp carbon monitoring and trend analysis"
        )
        self.site_name = site_name
        self._build_template()
    
    def _build_template(self):
        """Build temporal analysis template."""
        
        self.add_markdown_cell(f"""# Temporal Kelp Carbon Analysis

**Site:** {self.site_name}  
**Analysis Type:** Multi-temporal Trend Analysis  
**Objective:** Quantify carbon sequestration rates and temporal variability  

## Overview

This notebook analyzes temporal changes in kelp carbon stocks to calculate sequestration rates and identify trends.
""")
        
        self.add_code_cell("""# Import libraries for temporal analysis
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from kelpie_carbon_v1.analytics.enhanced_satellite_integration import EnhancedSatelliteAnalyzer

# Initialize temporal analyzer
analyzer = EnhancedSatelliteAnalyzer()

print("‚úÖ Temporal analysis environment ready")
print(f"üìä Analysis target: {site_name}")""")
        
        # Add more temporal-specific cells...
        self.add_markdown_cell("""## Temporal Data Loading

Load multi-temporal satellite datasets for trend analysis.
""")
        
        self.add_code_cell("""# Load temporal datasets
# This would load multiple time periods of satellite data
datasets = []  # List of xr.Dataset objects
timestamps = []  # List of datetime objects

# Example temporal data loading
print("üìÖ Loading temporal datasets...")
print("‚ö†Ô∏è Replace with actual data loading code")

# Mock temporal data for demonstration
for i in range(5):  # 5 time periods
    # Create mock dataset for each time period
    mock_dataset = None  # Replace with actual data loading
    mock_timestamp = datetime.now() - timedelta(days=30*i)
    
    datasets.append(mock_dataset)
    timestamps.append(mock_timestamp)

print(f"‚úÖ Loaded {len(datasets)} temporal datasets")""")

class JupyterTemplateManager:
    """Manager for Jupyter notebook templates."""
    
    def __init__(self):
        self.templates = {
            'scientific_analysis': ScientificAnalysisTemplate,
            'temporal_analysis': TemporalAnalysisTemplate
        }
    
    def generate_template(self, template_type: str, output_path: str, **kwargs) -> str:
        """Generate a Jupyter notebook template.
        
        Args:
            template_type: Type of template to generate
            output_path: Path to save the notebook
            **kwargs: Additional parameters for template
            
        Returns:
            Path to generated notebook
        """
        if template_type not in self.templates:
            raise ValueError(f"Unknown template type: {template_type}")
        
        template_class = self.templates[template_type]
        template = template_class(**kwargs)
        notebook_content = template.generate_notebook()
        
        # Ensure output directory exists
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        # Write notebook file
        with open(output_path, 'w') as f:
            json.dump(notebook_content, f, indent=2)
        
        logger.info(f"Generated {template_type} template at {output_path}")
        return output_path
    
    def list_available_templates(self) -> List[str]:
        """List all available template types."""
        return list(self.templates.keys())

def create_jupyter_template_manager() -> JupyterTemplateManager:
    """Factory function to create Jupyter template manager."""
    return JupyterTemplateManager() 