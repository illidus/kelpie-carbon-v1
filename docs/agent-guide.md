# ğŸ¤– AI Agent Guide - Kelpie Carbon v1

**Last Updated**: January 9, 2025  
**Structure Version**: 2.0 (Post-Reorganization)

This guide provides comprehensive instructions for AI agents working on the Kelpie Carbon v1 project. **Follow this guide carefully to maintain the established organizational structure.**

---

## ğŸ“‹ **Project Overview**

### **Project Details**
- **Name**: Kelpie Carbon v1
- **Purpose**: Kelp forest carbon sequestration assessment using satellite imagery
- **Tech Stack**: FastAPI + Python 3.12, Leaflet.js, Sentinel-2 data
- **Package Path**: `src/kelpie_carbon_v1/`
- **CLI Entry**: `kelpie-carbon-v1`
- **Status**: Production-ready (All 5 phases complete)

### **Current Capabilities** âœ…
- âœ… Real-time Sentinel-2 satellite data processing
- âœ… Interactive web interface with progressive loading
- âœ… Spectral index calculations (NDVI, FAI, NDRE)
- âœ… Machine learning kelp detection
- âœ… Carbon sequestration estimation
- âœ… Comprehensive test suite (205 tests)
- âœ… Complete documentation

---

## ğŸ—ï¸ **Project Structure (CRITICAL - Follow Exactly)**

### **Documentation Organization**
```
docs/
â”œâ”€â”€ README.md                          # ğŸ“š NAVIGATION HUB - Start here
â”œâ”€â”€ PROJECT_SUMMARY.md                 # Project overview
â”œâ”€â”€ USER_GUIDE.md                      # End-user documentation  
â”œâ”€â”€ DEVELOPER_ONBOARDING.md            # Developer setup
â”œâ”€â”€ DEVELOPMENT_GUIDE.md               # Development workflows
â”œâ”€â”€ ARCHITECTURE.md                    # System architecture
â”œâ”€â”€ API_REFERENCE.md                   # API documentation
â”œâ”€â”€ TESTING_GUIDE.md                   # Testing strategies
â”œâ”€â”€ DEPLOYMENT_GUIDE.md                # Production deployment
â”œâ”€â”€ SATELLITE_IMAGERY_FEATURE.md       # Satellite processing
â”œâ”€â”€ web-interface.md                   # Frontend documentation
â”œâ”€â”€ agent-guide.md                     # This file - AI agent guide
â”‚
â”œâ”€â”€ research/                          # ğŸ”¬ Research & validation docs
â”‚   â”œâ”€â”€ README.md                      # Research navigation
â”‚   â”œâ”€â”€ VALIDATION_DATA_FRAMEWORK.md   # SKEMA validation
â”‚   â”œâ”€â”€ RED_EDGE_ENHANCEMENT_SPEC.md   # NDRE research
â”‚   â”œâ”€â”€ SKEMA_INTEGRATION_TASK_LIST.md # Research tasks
â”‚   â”œâ”€â”€ SKEMA_RESEARCH_SUMMARY.md      # Research findings
â”‚   â””â”€â”€ NDRE_IMPLEMENTATION_SUCCESS.md # Implementation results
â”‚
â””â”€â”€ implementation/                    # ğŸ“‹ Historical implementation docs
    â”œâ”€â”€ README.md                      # Implementation navigation
    â”œâ”€â”€ [Phase implementation summaries]
    â”œâ”€â”€ [Task completion records]
    â”œâ”€â”€ [Optimization documentation]
    â””â”€â”€ [Status tracking files]
```

### **Test Organization**
```
tests/
â”œâ”€â”€ README.md                          # ğŸ“– Test suite guide
â”œâ”€â”€ conftest.py                        # Shared test configuration
â”‚
â”œâ”€â”€ unit/                              # âš¡ Unit tests (fast, isolated)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ [12 unit test files]
â”‚
â”œâ”€â”€ integration/                       # ğŸ”— Integration tests (external APIs)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ [4 integration test files]
â”‚
â”œâ”€â”€ e2e/                              # ğŸŒ End-to-end tests (workflows)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ [1 comprehensive test file]
â”‚
â””â”€â”€ performance/                       # âš¡ Performance tests
    â”œâ”€â”€ __init__.py
    â””â”€â”€ [2 performance test files]
```

---

## ğŸ“– **Documentation Standards (MANDATORY)**

### **File Placement Rules**
1. **Core Documentation**: Place in `docs/` root
   - User guides, API docs, architecture, deployment
   - **Examples**: `USER_GUIDE.md`, `API_REFERENCE.md`

2. **Research Documentation**: Place in `docs/research/`
   - Validation frameworks, scientific specifications
   - **Examples**: New SKEMA research, spectral analysis studies

3. **Implementation History**: Place in `docs/implementation/`
   - Task summaries, optimization records, status updates
   - **Examples**: Future implementation summaries, troubleshooting docs

### **New File Creation Checklist**
Before creating ANY new documentation file:

1. âœ… **Determine Category**: Core, Research, or Implementation?
2. âœ… **Check Existing**: Does similar documentation already exist?
3. âœ… **Update READMEs**: Add entry to appropriate directory README
4. âœ… **Add Cross-References**: Link from related documents
5. âœ… **Follow Naming**: Use clear, descriptive filenames

### **Documentation Templates**

#### **Implementation Summary Template**
```markdown
# [Feature/Task] Implementation Summary

**Date**: [Date]
**Status**: [COMPLETED/IN_PROGRESS/BLOCKED]
**Type**: [Feature/Bug Fix/Optimization/Research]

## ğŸ¯ Objective
[What was implemented/changed]

## âœ… Completed Tasks
- [ ] Task 1
- [ ] Task 2

## ğŸ“Š Results
[Metrics, performance improvements, etc.]

## ğŸ”— Related Documentation
- [Link to related docs]

## ğŸ§ª Testing
[Test results, coverage info]
```

#### **Research Document Template**
```markdown
# [Research Topic] - [Brief Description]

**Date**: [Date]
**Research Type**: [Validation/Analysis/Integration]
**Status**: [COMPLETED/ONGOING]

## ğŸ”¬ Research Objective
[What was studied/validated]

## ğŸ“Š Methodology
[How research was conducted]

## ğŸ“ˆ Results
[Findings, data, conclusions]

## ğŸ”— Implementation Impact
[How this affects the codebase]
```

---

## ğŸ§ª **Testing Standards (CRITICAL)**

### **Test Categorization Rules**
1. **Unit Tests** (`tests/unit/`): 
   - Fast, isolated, no external dependencies
   - Test individual functions/classes
   - **Example**: API endpoint logic, data models

2. **Integration Tests** (`tests/integration/`):
   - Test component interactions
   - May use external APIs (satellite data)
   - **Example**: Real satellite data fetching

3. **End-to-End Tests** (`tests/e2e/`):
   - Test complete user workflows
   - Full system integration
   - **Example**: Complete analysis pipeline

4. **Performance Tests** (`tests/performance/`):
   - Test optimization and resource usage
   - **Example**: Caching effectiveness, response times

### **Test File Naming**
- `test_[module_name].py` for unit tests
- `test_[feature]_integration.py` for integration tests
- `test_[workflow]_comprehensive.py` for e2e tests
- `test_[aspect]_performance.py` for performance tests

### **Test Execution Commands**
```bash
# Unit tests (fast feedback)
pytest tests/unit/ -v

# Integration tests
pytest tests/integration/ -v

# End-to-end tests
pytest tests/e2e/ -v

# Performance tests
pytest tests/performance/ -v

# All tests
pytest -v
```

---

## ğŸ› ï¸ **Development Workflow**

### **Before Making Changes**
1. âœ… **Read Documentation Index**: Start at `docs/README.md`
2. âœ… **Check Architecture**: Review `docs/ARCHITECTURE.md`
3. âœ… **Review Tests**: Check `tests/README.md` for testing strategy
4. âœ… **Understand Structure**: Follow the organization established

### **Code Changes Process**
1. **Identify Impact**: What components are affected?
2. **Update Tests**: Add/modify tests in appropriate category
3. **Update Documentation**: Update relevant docs
4. **Run Tests**: Ensure all tests pass
5. **Update Cross-References**: Fix any broken links

### **Quality Checks**
```bash
# Run all tests
poetry run pytest

# Check code formatting
poetry run black --check src/ tests/

# Type checking
poetry run mypy src/

# Lint checking
poetry run flake8 src/ tests/
```

---

## ğŸ“ **Documentation Maintenance**

### **When Adding New Features**
1. **Update Core Docs**: Modify `API_REFERENCE.md`, `USER_GUIDE.md` as needed
2. **Add Implementation Summary**: Create summary in `docs/implementation/`
3. **Update Architecture**: If system design changes
4. **Cross-Reference**: Link from related documents

### **When Adding Research**
1. **Create Research Doc**: Place in `docs/research/`
2. **Update Research README**: Add entry to `docs/research/README.md`
3. **Link Implementation**: Reference from implementation summaries
4. **Update Main Index**: Add to `docs/README.md` if significant

### **When Completing Tasks**
1. **Create Summary**: Document what was done
2. **Move to Implementation**: Place in `docs/implementation/`
3. **Update Status**: Mark tasks as complete
4. **Archive Temporary Files**: Remove temporary documentation

---

## ğŸš¨ **Critical Rules (DO NOT BREAK)**

### **Structure Preservation**
1. âŒ **NEVER** put implementation summaries in `docs/` root
2. âŒ **NEVER** put research docs in `docs/` root  
3. âŒ **NEVER** mix test types in wrong directories
4. âŒ **NEVER** skip updating READMEs when adding files
5. âŒ **NEVER** break cross-references without fixing them

### **Required Actions**
1. âœ… **ALWAYS** update appropriate README when adding files
2. âœ… **ALWAYS** categorize tests correctly
3. âœ… **ALWAYS** add cross-references to related documents
4. âœ… **ALWAYS** follow established naming conventions
5. âœ… **ALWAYS** test changes before committing

### **Documentation Links**
1. âœ… **ALWAYS** use relative paths for internal links
2. âœ… **ALWAYS** update `docs/README.md` for major additions
3. âœ… **ALWAYS** check links work after moving files
4. âœ… **ALWAYS** maintain directory README files

---

## ğŸ—‚ï¸ **Future Implementation Summaries**

### **Storage Location**
All future implementation summaries MUST go in `docs/implementation/` with clear naming:
- `FEATURE_[NAME]_IMPLEMENTATION_SUMMARY.md`
- `BUGFIX_[ISSUE]_RESOLUTION_SUMMARY.md`
- `OPTIMIZATION_[ASPECT]_COMPLETION_SUMMARY.md`
- `RESEARCH_[TOPIC]_INTEGRATION_SUMMARY.md`

### **Required Content**
1. **Date and Status**
2. **Clear Objective**
3. **Tasks Completed**
4. **Results/Metrics**
5. **Test Results**
6. **Related Documentation Links**

### **Directory README Update**
ALWAYS add new summaries to `docs/implementation/README.md` under the appropriate category.

---

## ğŸ”„ **Version Control Best Practices**

### **Commit Strategy**
1. **Small, Focused Commits**: One logical change per commit
2. **Clear Messages**: Use conventional commit format
3. **Test Before Commit**: Ensure tests pass
4. **Document Changes**: Update relevant documentation

### **Conventional Commits**
```bash
feat(api): add new kelp detection endpoint
fix(imagery): resolve RGB composite caching issue
docs(guide): update agent guide with new structure
test(unit): add comprehensive model validation tests
refactor(core): improve satellite data processing efficiency
```

---

## ğŸ¯ **Success Metrics**

### **Code Quality**
- âœ… All tests passing (currently 205 passed, 7 skipped)
- âœ… Clean code following established patterns
- âœ… Proper error handling and logging
- âœ… Type hints and documentation

### **Documentation Quality**
- âœ… Clear, up-to-date documentation
- âœ… Proper file organization
- âœ… Working cross-references
- âœ… Comprehensive implementation tracking

### **Structural Integrity**
- âœ… Files in correct directories
- âœ… Updated README files
- âœ… Maintained test categorization
- âœ… Preserved architectural patterns

---

## ğŸ“ **Getting Help**

### **Documentation Resources**
1. **Start Here**: `docs/README.md` - Navigation hub
2. **Development**: `docs/DEVELOPER_ONBOARDING.md` - Setup guide
3. **Testing**: `tests/README.md` - Test guidance
4. **Architecture**: `docs/ARCHITECTURE.md` - System design

### **Common Issues**
1. **Test Failures**: Check test category and dependencies
2. **Documentation Links**: Verify relative paths are correct
3. **File Placement**: Follow the established directory structure
4. **Integration**: Ensure external APIs are accessible

---

**Remember**: This organizational structure was carefully designed for maintainability. Following these guidelines ensures the codebase remains clean, navigable, and sustainable for future development.

**Last Verification**: All 205 tests passing âœ…  
**Structure Status**: Fully implemented and documented âœ…